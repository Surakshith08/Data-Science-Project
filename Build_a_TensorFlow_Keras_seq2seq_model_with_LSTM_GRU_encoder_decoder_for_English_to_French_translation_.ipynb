{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Practical 11\n",
        "\n",
        "**Aim:** Build a sequence-to-sequence (seq2seq) model using TensorFlow/Keras for a simple\n",
        "machine translation task (e.g., translating English sentences to French). Use an LSTM or GRU for both\n",
        "the encoder and decoder."
      ],
      "metadata": {
        "id": "eRwPNoy-Ysnc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV6gMTJhYeaG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 Small toy parallel corpus\n",
        "\n",
        "en_sentences = [\n",
        "\"i am a student\",\n",
        "\"you are a teacher\",\n",
        "\"he is a doctor\",\n",
        "\"she is a nurse\",\n",
        "\"we are friends\",\n",
        "\"they are engineers\",\n",
        "\"i like apples\",\n",
        "\"you like oranges\",\n",
        "\"we love music\",\n",
        "\"they play football\"\n",
        "]"
      ],
      "metadata": {
        "id": "Lt7uY3oGYzkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theory:**\n",
        "\n",
        "* Sequence-to-Sequence (Seq2Seq) Model: This architecture is commonly used for tasks where the input and output are sequences, such as machine translation. It consists of two main parts:\n",
        "* Encoder: Processes the input sequence and compresses it into a fixed-length context vector (or set of state vectors) that theoretically captures the meaning of the input.\n",
        "* Decoder: Takes the context vector from the encoder and generates the output sequence one element at a time.\n",
        "* Recurrent Neural Networks (RNNs): Both the encoder and decoder typically use RNNs like LSTMs or GRUs, which are designed to handle sequential data by maintaining an internal state that remembers information from previous steps.\n",
        "* Teacher Forcing: During training, the decoder is often fed the correct previous target token as input to predict the next token. This helps the model learn the correct output sequence more quickly.\n",
        "* Greedy Decoding: During inference (translation), the decoder predicts the next token with the highest probability at each step. This is a simple decoding strategy but can sometimes lead to suboptimal translations.\n",
        "* Padding and Tokenization: Text data needs to be converted into numerical sequences for the model. Tokenization breaks down sentences into words or sub-word units, and padding ensures all sequences have the same length."
      ],
      "metadata": {
        "id": "vNlGgLzMddb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr_sentences = [\n",
        "\"je suis un étudiant\",\n",
        "\n",
        "\"tu es un professeur\",\n",
        "\"il est un médecin\",\n",
        "\"elle est une infirmière\",\n",
        "\"nous sommes des amis\",\n",
        "\"ils sont des ingénieurs\",\n",
        "\"j'aime les pommes\",\n",
        "\"tu aimes les oranges\",\n",
        "\"nous aimons la musique\",\n",
        "\"ils jouent au football\"\n",
        "]"
      ],
      "metadata": {
        "id": "iQ4qA8TvY7zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize the sentences\n",
        "make the sentences of equal length\n"
      ],
      "metadata": {
        "id": "P-eNOeYwZAFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add start/end tokens on target side\n",
        "fr_sentences_in = [f\"<sos> {s}\" for s in fr_sentences]\n",
        "fr_sentences_out = [f\"{s} <eos>\" for s in fr_sentences]"
      ],
      "metadata": {
        "id": "kB4GrZWAY_uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Tokenize\n",
        "def make_tokenizer(texts, oov_token=\"<unk>\"):\n",
        "  t = Tokenizer(oov_token=oov_token, filters=\"\") # keep punctuation if any\n",
        "  t.fit_on_texts(texts)\n",
        "  return t\n",
        "\n",
        "# Source (English)\n",
        "src_tok = make_tokenizer(en_sentences)\n",
        "src_vocab = len(src_tok.word_index) + 1\n",
        "\n",
        "# Target (French) uses both input (with <sos>) and output (with <eos>)\n",
        "tgt_tok = make_tokenizer(fr_sentences_in + fr_sentences_out)\n",
        "\n",
        "tgt_vocab = len(tgt_tok.word_index) + 1\n",
        "\n",
        "# Sequences\n",
        "src_seq = src_tok.texts_to_sequences(en_sentences)\n",
        "tgt_seq_in = tgt_tok.texts_to_sequences(fr_sentences_in)\n",
        "tgt_seq_out = tgt_tok.texts_to_sequences(fr_sentences_out)\n",
        "\n",
        "# Max lengths\n",
        "max_src_len = max(len(s) for s in src_seq)\n",
        "max_tgt_len = max(len(s) for s in tgt_seq_in) # in and out have same length\n",
        "\n",
        "# Pad\n",
        "src_seq = pad_sequences(src_seq, maxlen=max_src_len, padding=\"post\")\n",
        "tgt_seq_in = pad_sequences(tgt_seq_in, maxlen=max_tgt_len, padding=\"post\")\n",
        "tgt_seq_out = pad_sequences(tgt_seq_out, maxlen=max_tgt_len, padding=\"post\")"
      ],
      "metadata": {
        "id": "x3xoQAinZKM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the LSTM or GRU model"
      ],
      "metadata": {
        "id": "ViOsa3ebZRVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Build the model\n",
        "EMB_SRC = 64\n",
        "EMB_TGT = 64\n",
        "HID = 128\n",
        "USE_GRU = False # set True to switch to GRU\n",
        "\n",
        "# Encoder\n",
        "enc_inputs = Input(shape=(max_src_len,), name=\"encoder_input\")\n",
        "enc_emb = Embedding(input_dim=src_vocab, output_dim=EMB_SRC,\n",
        "name=\"enc_embedding\")(enc_inputs)\n",
        "\n",
        "if USE_GRU:\n",
        "  enc_rnn, enc_state = GRU(HID, return_state=True, name=\"encoder_gru\")(enc_emb)\n",
        "  enc_states = [enc_state]\n",
        "else:\n",
        "  enc_rnn, state_h, state_c = LSTM(HID, return_sequences=False, return_state=True,\n",
        "name=\"encoder_lstm\")(enc_emb)\n",
        "  enc_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "dec_inputs = Input(shape=(max_tgt_len,), name=\"decoder_input\")\n",
        "dec_emb = Embedding(input_dim=tgt_vocab, output_dim=EMB_TGT,\n",
        "name=\"dec_embedding\")(dec_inputs)\n",
        "\n",
        "if USE_GRU:\n",
        "  dec_rnn = GRU(HID, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
        "  dec_outputs, _ = dec_rnn(dec_emb, initial_state=enc_states)\n",
        "else:\n",
        "  dec_rnn = LSTM(HID, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "  dec_outputs, _, _ = dec_rnn(dec_emb, initial_state=enc_states)\n",
        "\n",
        "dec_dense = Dense(tgt_vocab, activation=\"softmax\", name=\"decoder_dense\")\n",
        "dec_logits = dec_dense(dec_outputs) # (batch, max_tgt_len, tgt_vocab)\n",
        "\n",
        "# Train model (teacher forcing)\n",
        "model = Model([enc_inputs, dec_inputs], dec_logits)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# Targets must be rank-3 for sparse CE: (batch, time, 1)\n",
        "tgt_out_expanded = np.expand_dims(tgt_seq_out, -1)\n",
        "\n",
        "# Early stopping to avoid overfitting on tiny dataset\n",
        "\n",
        "es = EarlyStopping(monitor=\"loss\", patience=8, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "[src_seq, tgt_seq_in], tgt_out_expanded,\n",
        "batch_size=4,\n",
        "epochs=200,\n",
        "callbacks=[es],\n",
        "verbose=0 # change to 1 to watch training\n",
        ")\n",
        "\n",
        "print(f\"Trained for {len(history.history['loss'])} epochs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "sAKlEEtJZT7-",
        "outputId": "eba80f8f-54ed-4d66-f012-9c517dbc35d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m1,600\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m2,240\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m98,816\u001b[0m │ enc_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m),  │     \u001b[38;5;34m98,816\u001b[0m │ dec_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m35\u001b[0m)     │      \u001b[38;5;34m4,515\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ enc_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dec_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,987\u001b[0m (804.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,987</span> (804.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,987\u001b[0m (804.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,987</span> (804.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained for 200 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Build inference models\n",
        "# Encoder model (same as train, outputs states)\n",
        "if USE_GRU:\n",
        "  encoder_model = Model(enc_inputs, enc_states[0])\n",
        "else:\n",
        "  encoder_model = Model(enc_inputs, enc_states)\n",
        "\n",
        "# Decoder inference: one step at a time\n",
        "# Inputs: current token + previous state(s)\n",
        "dec_token_input = Input(shape=(1,), name=\"dec_token_input\")\n",
        "dec_token_emb = model.get_layer(\"dec_embedding\")(dec_token_input)\n",
        "\n",
        "if USE_GRU:\n",
        "  inf_state_in = Input(shape=(HID,), name=\"state_in\")\n",
        "  dec_out_step, state_out = dec_rnn(dec_token_emb, initial_state=[inf_state_in])\n",
        "  dec_step_probs = dec_dense(dec_out_step)\n",
        "  decoder_model = Model([dec_token_input, inf_state_in], [dec_step_probs, state_out])\n",
        "\n",
        "else:\n",
        "  inf_state_h = Input(shape=(HID,), name=\"state_h_in\")\n",
        "  inf_state_c = Input(shape=(HID,), name=\"state_c_in\")\n",
        "  dec_out_step, out_h, out_c = dec_rnn(dec_token_emb, initial_state=[inf_state_h, inf_state_c])\n",
        "  dec_step_probs = dec_dense(dec_out_step)\n",
        "  decoder_model = Model([dec_token_input, inf_state_h, inf_state_c],\n",
        "[dec_step_probs, out_h, out_c])\n"
      ],
      "metadata": {
        "id": "n8U7_6SvaLSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 Greedy decoding helper\n",
        "\n",
        "sos_id = tgt_tok.word_index.get(\"<sos>\")\n",
        "eos_id = tgt_tok.word_index.get(\"<eos>\")\n",
        "\n",
        "index_to_tgt = {v: k for k, v in tgt_tok.word_index.items()}\n",
        "\n",
        "def translate_sentence(sentence_en, max_len=20):\n",
        "# Encode source\n",
        "  seq = src_tok.texts_to_sequences([sentence_en])\n",
        "  seq = pad_sequences(seq, maxlen=max_src_len, padding=\"post\")\n",
        "  if USE_GRU:\n",
        "    state = encoder_model.predict(seq, verbose=0)\n",
        "  else:\n",
        "    state_h, state_c = encoder_model.predict(seq, verbose=0)\n",
        "\n",
        "# Start with <sos>\n",
        "  target_token = np.array([[sos_id]], dtype=\"int32\")\n",
        "  output_tokens = []\n",
        "\n",
        "  for _ in range(max_len):\n",
        "    if USE_GRU:\n",
        "      probs, state = decoder_model.predict([target_token, state], verbose=0)\n",
        "\n",
        "    else:\n",
        "      probs, state_h, state_c = decoder_model.predict([target_token, state_h, state_c], verbose=0)\n",
        "\n",
        "    next_id = np.argmax(probs[0, 0]) # greedy\n",
        "    if next_id == eos_id or next_id == 0:\n",
        "      break\n",
        "    output_tokens.append(index_to_tgt.get(next_id, \"<unk>\"))\n",
        "    target_token = np.array([[next_id]], dtype=\"int32\")\n",
        "\n",
        "  return \" \".join(output_tokens)"
      ],
      "metadata": {
        "id": "xFsJFkd-aVcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#Testing the code\"\"\"\n",
        "\n",
        "# Try a few translations\n",
        "tests = [\n",
        "\"i am a student\",\n",
        "\"you like oranges\",\n",
        "\"we love music\",\n",
        "\"they play football\",\n",
        "\"she is a nurse\"\n",
        "]\n",
        "\n",
        "for s in tests:\n",
        "  print(f\"EN: {s}\")\n",
        "  print(f\"FR: {translate_sentence(s)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1e7dTIbaayr",
        "outputId": "5d099891-f368-488d-83a8-f29dd61e148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EN: i am a student\n",
            "FR: je suis un étudiant\n",
            "\n",
            "EN: you like oranges\n",
            "FR: tu aimes les oranges\n",
            "\n",
            "EN: we love music\n",
            "FR: nous aimons la musique\n",
            "\n",
            "EN: they play football\n",
            "FR: ils jouent au football\n",
            "\n",
            "EN: she is a nurse\n",
            "FR: elle est une infirmière\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "The model successfully translates the given English sentences to their corresponding French translations in the small toy dataset.\n",
        "The translations are accurate for the examples provided.\n",
        "The model was trained for 200 epochs and stopped early based on the defined criteria.\n",
        "The model summary shows the architecture with embedding layers, LSTM (or GRU) layers, and a dense output layer with a softmax activation for probability distribution over the target vocabulary.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The built seq2seq model, using LSTM (or GRU) layers for encoding and decoding, is capable of performing simple machine translation on the small, limited dataset. The training process converged, and the greedy decoding strategy produced correct translations for the test sentences. While effective on this small scale, larger and more complex datasets, along with more advanced techniques like attention mechanisms and beam search decoding, would be necessary for practical machine translation."
      ],
      "metadata": {
        "id": "K26IhEUSd1oJ"
      }
    }
  ]
}